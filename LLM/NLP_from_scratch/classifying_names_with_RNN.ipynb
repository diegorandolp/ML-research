{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classifying names with RNN\n",
    "\n",
    "Classify few thousand surnames from 18 languages and predict the language based on the spelling\n",
    "\n",
    "Data: https://download.pytorch.org/tutorial/data.zip"
   ],
   "id": "7768dd382ca46a4e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.127924Z",
     "start_time": "2025-07-24T01:56:18.124002Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(f\"[DEVICE] {torch.get_default_device()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEVICE] cuda:0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing the data",
   "id": "388b544685b28ec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.196363Z",
     "start_time": "2025-07-24T01:56:18.193672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "allowed_characters = string.ascii_letters + \".,;'\" + \"_\"\n",
    "n_letters = len(allowed_characters)\n",
    "\n",
    "# convert to unicode to ascii to limit the RNN input parameters\n",
    "# eg. using one-hot encoding you need 128 parameters with ASCII\n",
    "# while thousands parameters with Unicode\n",
    "# So, the RNN training is faster and simpler\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        # decompose the combined chars\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in allowed_characters\n",
    "    )\n"
   ],
   "id": "88e9bf64606e672e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.254569Z",
     "start_time": "2025-07-24T01:56:18.251276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_test = \"Ślusàrski\"\n",
    "print(f\"[UNICODE] {word_test}\")\n",
    "print(f\"[ASCII] {unicodeToAscii(word_test)}\")\n"
   ],
   "id": "dd6e5cdbaa234755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNICODE] Ślusàrski\n",
      "[ASCII] Slusarski\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Name to tensor\n",
    "Using one hot encoding, we represent chars as tensors, so tensors will have the size of the vocabulary"
   ],
   "id": "91c60858602fb92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.317304Z",
     "start_time": "2025-07-24T01:56:18.314298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the letter index\n",
    "def letterToIndex(letter):\n",
    "    # if letter in unknown\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find('_')\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "# word to tensor\n",
    "def lineToTensor(line):\n",
    "    # RNN, GRU and LTSM have this expected input shape\n",
    "    # (seq_len, batch, input_size), where:\n",
    "    # seq_len: number of steps in the network, 1 step is 1 letter\n",
    "    # batch: sequences in parallel, 1 is for 1 letter at a time\n",
    "    # input_size: size of vocabulary\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ],
   "id": "4206cdadd453f3ba",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.373216Z",
     "start_time": "2025-07-24T01:56:18.368697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"[TEST] a:\")\n",
    "print(lineToTensor(\"a\"))\n",
    "\n",
    "print(f\"[TEST] Ahn:\")\n",
    "print(lineToTensor(\"Ahn\"))"
   ],
   "id": "d08f8cce7b70de47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] a:\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "[TEST] Ahn:\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare data",
   "id": "dada1c6e698afcea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:18.437286Z",
     "start_time": "2025-07-24T01:56:18.429602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # metadata\n",
    "        self.data_dir = data_dir\n",
    "        self.load_time = time.localtime\n",
    "        # set of all languages\n",
    "        labels_set = set()\n",
    "        # Names and languages by strings and tensors\n",
    "        self.data = []\n",
    "        self.data_tensors = []\n",
    "        self.labels = []\n",
    "        self.labels_tensors = []\n",
    "        # read data from .txt\n",
    "        text_files = glob.glob(os.path.join(data_dir, \"*.txt\"))\n",
    "        for filename in text_files:\n",
    "            label = os.path.splitext(os.path.basename(filename))[0]\n",
    "            labels_set.add(label)\n",
    "            lines = open(filename, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "            for name in lines:\n",
    "                self.data.append(name)\n",
    "                self.data_tensors.append(lineToTensor(name))\n",
    "                self.labels.append(label)\n",
    "        # labels to tensor\n",
    "        self.labels_uniq = list(labels_set)\n",
    "        for idx in range(len(self.labels)):\n",
    "            # the tensor of the label is its index in the list of unique labels\n",
    "            temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n",
    "            self.labels_tensors.append(temp_tensor)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        data_item = self.data[idx]\n",
    "        data_label = self.labels[idx]\n",
    "        data_tensor = self.data_tensors[idx]\n",
    "        label_tensor = self.labels_tensors[idx]\n",
    "\n",
    "        return label_tensor, data_tensor, data_label, data_item"
   ],
   "id": "bc26c89cd29a9512",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:20.627749Z",
     "start_time": "2025-07-24T01:56:18.478353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alldata = NamesDataset(\"./data/names\")\n",
    "print(f\"[DATA] Loaded {len(alldata)} names\")\n",
    "print(f\"[EXAMPLE]\")\n",
    "print(alldata[0])"
   ],
   "id": "e86d1c710758365d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] Loaded 20074 names\n",
      "[EXAMPLE]\n",
      "(tensor([0], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0'), 'Vietnamese', 'Nguyen')\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T01:56:20.666429Z",
     "start_time": "2025-07-24T01:56:20.638948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here we are using Generator to set the device as gpu\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    alldata,\n",
    "    [0.85, 0.15],\n",
    "    generator=torch.Generator(device=device).manual_seed(2025)\n",
    ")\n",
    "\n",
    "print(f\"[TRAIN] {len(train_set)} examples\")\n",
    "print(f\"[TEST] {len(test_set)} examples\")\n"
   ],
   "id": "cf202532bb09284b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] 17063 examples\n",
      "[TEST] 3011 examples\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the network",
   "id": "b614b5fa03336402"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The RNN will have this architecture\n",
    "\n",
    "\n",
    "```text\n",
    "┌────────────┐         ┌───────────────────┐          ┌────────────┐\n",
    "│  x_t (t=0) │─▶ … ─▶ │  x_t (t=N-1)       │          │            │\n",
    "└────────────┘         └───────────────────┘          │  INPUT     │\n",
    "       │                        │                     │  SEQUENCE  │\n",
    "       ▼                        ▼                     │  (length N)│\n",
    "┌───────────────────────────────────────────────────────────────────┐\n",
    "│                           nn.RNN                                │\n",
    "│ ┌───────────┐   ┌───────────┐    ┌───────────┐                  │\n",
    "│ │  h₀       │──▶│  h₁       │──▶ …│  h_N‑1   │──▶ (take h_N‑1)   │\n",
    "│ └───────────┘   └───────────┘    └───────────┘                  │\n",
    "│          hidden_size‑dim hidden state chain                      │\n",
    "└───────────────────────────────────────────────────────────────────┘\n",
    "                                   │   final hidden state h_N‑1\n",
    "                                   ▼\n",
    "                       ┌────────────────────────┐\n",
    "                       │ nn.Linear              │\n",
    "                       │  (hidden_size →        │\n",
    "                       │   output_size)         │\n",
    "                       └────────────────────────┘\n",
    "                                   │   raw scores (“logits”)\n",
    "                                   ▼\n",
    "                       ┌────────────────────────┐\n",
    "                       │ nn.LogSoftmax (dim=1) │\n",
    "                       └────────────────────────┘\n",
    "                                   │   log‑probabilities\n",
    "                                   ▼\n",
    "                          ┌─────────────────┐\n",
    "                          │ ŷ  (predicted) │\n",
    "                          └─────────────────┘\n",
    "```\n"
   ],
   "id": "e2dd615a65986662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:02:18.059561Z",
     "start_time": "2025-07-24T02:02:18.054595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        # input_size: size of the embeddings\n",
    "        # hidden_size: arbitrary\n",
    "        # output_size: numbers of classes\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, line_tensor):\n",
    "        # rnn_out: output at every step,\n",
    "        # its size is (seq_len, batch, hidden_size)\n",
    "        # hidden: final state for each layer,\n",
    "        # its size is (num_layers*num_directions, batch, hidden_size)\n",
    "        # in this case CharRNN has only 1 layer and is unidirectional\n",
    "        rnn_out, hidden = self.rnn(line_tensor)\n",
    "        # hidden[0] because there is only 1 layer\n",
    "        output = self.h2o(hidden[0])\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output"
   ],
   "id": "12839d876bdc920e",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:02:20.954640Z",
     "start_time": "2025-07-24T02:02:20.948780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_hidden = 128\n",
    "# input_size=n_letters because one-hot encoding\n",
    "rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\n",
    "print(rnn)"
   ],
   "id": "817f3c8990ca75cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (rnn): RNN(57, 128)\n",
      "  (h2o): Linear(in_features=128, out_features=18, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:30:21.772942Z",
     "start_time": "2025-07-24T02:30:21.752227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initial test\n",
    "def label_from_output(output, output_labels):\n",
    "    top_n, top_i = output.topk(1) # greatest probability\n",
    "    label_i = top_i[0].item()\n",
    "    return output_labels[label_i], label_i\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input = lineToTensor(\"Albert\")\n",
    "output = rnn.forward(input) # 18 log probabilities\n",
    "print(output)\n",
    "print(label_from_output(output, alldata.labels_uniq))"
   ],
   "id": "7b40acf3482b1473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8434, -2.8473, -2.8624, -2.8832, -2.8586, -2.8570, -2.8839, -2.9410,\n",
      "         -2.8990, -2.9749, -2.9917, -2.9401, -2.8129, -2.9355, -2.8462, -2.8328,\n",
      "         -2.9229, -2.9159]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
      "('Irish', 12)\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "The standard way to compute gradients is using mini-batches. Mini-batches allows the use of parallelization and the batches introduce noise that helps to reach flat minimum(good model) instead of sharp minimum(overfitted model). The last situation often occurs if you compute the gradients using all dataset.\n",
    "\n",
    "It works because the gradient computed using all the dataset can be approximated using mini-batches:\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta)=\\frac1N\\sum_{i=1}^{N}\\nabla_\\theta\\ell_i.\n",
    "$$\n",
    "This is the gradient using mini-batches and across the time it will reach the same value as using the full dataset, but faster and with better generalisation due to noise introduced with each batch.\n",
    "\n",
    "$\\mathcal B\\subset\\mathcal D$\n",
    "\n",
    "$$\n",
    "\\widehat{\\nabla_\\theta J}\\;=\\;\\frac1{|\\mathcal B|}\\sum_{i\\in\\mathcal B}\\nabla_\\theta\\ell_i.\n",
    "$$"
   ],
   "id": "e6434204cd12d08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T05:08:15.448804Z",
     "start_time": "2025-07-24T05:08:15.441074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train(rnn,\n",
    "          training_data,\n",
    "          n_epoch = 10,\n",
    "          n_batch_size = 64,\n",
    "          report_every = 50,\n",
    "          learning_rate = 0.2,\n",
    "          criterion = nn.NLLLoss()):\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    rnn.train()\n",
    "    optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"[TRAIN] {len(training_data)} training examples\")\n",
    "\n",
    "    for iter in range(1, n_epoch + 1):\n",
    "        rnn.zero_grad() # clear gradients\n",
    "\n",
    "        # create minibatches as we can't use dataloaders\n",
    "        # because each of our names is a different length\n",
    "        batches = list(range(len(training_data)))\n",
    "        random.shuffle(batches)\n",
    "        batches = np.array_split(batches, len(batches) // n_batch_size)\n",
    "\n",
    "        for idx, batch in enumerate(batches):\n",
    "            batch_loss = 0\n",
    "            for i in batch:\n",
    "                (label_tensor, text_tensor, label, text) = training_data[i]\n",
    "                output = rnn.forward(text_tensor)\n",
    "                loss = criterion(output, label_tensor)\n",
    "                # sum the loss of individual examples across each\n",
    "                # batch due to:\n",
    "                # 1. we are using the sum instead of the mean\n",
    "                # 2. we are assuming the size of\n",
    "                # dataset is too high, so we use batches\n",
    "                batch_loss += loss\n",
    "            # updating parameters using mini-batch in large data sets\n",
    "            # approximates to update parameters using the full\n",
    "            # dataset\n",
    "            batch_loss.backward()\n",
    "            # clip the gradients to control them\n",
    "            # due to we are summing them\n",
    "            nn.utils.clip_grad_norm_(rnn.parameters(), 3)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            current_loss += batch_loss.item() / len(batch)\n",
    "        all_losses.append(current_loss/len(batches))\n",
    "        if iter % report_every == 0:\n",
    "            print(f\"[TRAIN] {iter} ({iter / n_epoch:.0%} \\t average batch loss = {all_losses[-1]})\")\n",
    "        current_loss = 0\n",
    "    return all_losses"
   ],
   "id": "6a9a1a8d5149423e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T05:12:38.375171Z",
     "start_time": "2025-07-24T05:09:51.285216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "all_losses = train(rnn, train_set, n_epoch=27, learning_rate=0.15, report_every=5)\n",
    "end = time.time()\n",
    "print(f\"[TRAIN] {end-start} seconds\")"
   ],
   "id": "8a89025e3c8ab686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] 17063 training examples\n",
      "[TRAIN] 5 (19% \t average batch loss = 0.8859527000583204)\n",
      "[TRAIN] 10 (37% \t average batch loss = 0.701222679332683)\n",
      "[TRAIN] 15 (56% \t average batch loss = 0.5911225259666018)\n",
      "[TRAIN] 20 (74% \t average batch loss = 0.5029936143381876)\n",
      "[TRAIN] 25 (93% \t average batch loss = 0.44447675389989116)\n",
      "[TRAIN] 167.0872118473053 seconds\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T05:32:58.481697Z",
     "start_time": "2025-07-24T05:32:58.475558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_test = lineToTensor(\"Hassam\")\n",
    "output = rnn.forward(tensor_test)\n",
    "print(label_from_output(output, alldata.labels_uniq))"
   ],
   "id": "196332a12377f0c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arabic', 7)\n"
     ]
    }
   ],
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
