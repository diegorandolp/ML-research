{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classifying names with RNN\n",
    "\n",
    "Classify few thousand surnames from 18 languages and predict the language based on the spelling\n",
    "\n",
    "Data: https://download.pytorch.org/tutorial/data.zip"
   ],
   "id": "7768dd382ca46a4e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T00:55:39.787371Z",
     "start_time": "2025-07-22T00:55:36.606506Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(f\"[DEVICE] {torch.get_default_device()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEVICE] cuda:0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing the data",
   "id": "388b544685b28ec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T01:13:48.170645Z",
     "start_time": "2025-07-22T01:13:48.165473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "allowed_characters = string.ascii_letters + \".,;'\" + \"_\"\n",
    "n_letters = len(allowed_characters)\n",
    "\n",
    "# convert to unicode to ascii to limit the RNN input parameters\n",
    "# eg. using one-hot encoding you need 128 parameters with ASCII\n",
    "# while thousands parameters with Unicode\n",
    "# So, the RNN training is faster and simpler\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        # decompose the combined chars\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in allowed_characters\n",
    "    )\n"
   ],
   "id": "88e9bf64606e672e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T01:13:49.296538Z",
     "start_time": "2025-07-22T01:13:49.290163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_test = \"Ślusàrski\"\n",
    "print(f\"[UNICODE] {word_test}\")\n",
    "print(f\"[ASCII] {unicodeToAscii(word_test)}\")\n"
   ],
   "id": "dd6e5cdbaa234755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNICODE] Ślusàrski\n",
      "[ASCII] Slusarski\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Name to tensor\n",
    "Using one hot encoding, we represent chars as tensors, so tensors will have the size of the vocabulary"
   ],
   "id": "91c60858602fb92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:10:05.734676Z",
     "start_time": "2025-07-22T04:10:05.729110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the letter index\n",
    "def letterToIndex(letter):\n",
    "    # if letter in unknown\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find('_')\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "# word to tensor\n",
    "def lineToTensor(line):\n",
    "    # RNN, GRU and LTSM have this expected input shape\n",
    "    # (seq_len, batch, input_size), where:\n",
    "    # seq_len: number of steps in the network, 1 step is 1 letter\n",
    "    # batch: sequences in parallel, 1 is for 1 letter at a time\n",
    "    # input_size: size of vocabulary\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ],
   "id": "4206cdadd453f3ba",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:12:29.199675Z",
     "start_time": "2025-07-22T04:12:29.057824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"[TEST] a:\")\n",
    "print(lineToTensor(\"a\"))\n",
    "\n",
    "print(f\"[TEST] Ahn:\")\n",
    "print(lineToTensor(\"Ahn\"))"
   ],
   "id": "d08f8cce7b70de47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] a:\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "[TEST] Ahn:\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare data",
   "id": "dada1c6e698afcea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T05:01:48.992910Z",
     "start_time": "2025-07-22T05:01:48.984072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # metadata\n",
    "        self.data_dir = data_dir\n",
    "        self.load_time = time.localtime\n",
    "        # set of all languages\n",
    "        labels_set = set()\n",
    "        # Names and languages by strings and tensors\n",
    "        self.data = []\n",
    "        self.data_tensors = []\n",
    "        self.labels = []\n",
    "        self.labels_tensors = []\n",
    "        # read data from .txt\n",
    "        text_files = glob.glob(os.path.join(data_dir, \"*.txt\"))\n",
    "        for filename in text_files:\n",
    "            label = os.path.splitext(os.path.basename(filename))[0]\n",
    "            labels_set.add(label)\n",
    "            lines = open(filename, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "            for name in lines:\n",
    "                self.data.append(name)\n",
    "                self.data_tensors.append(lineToTensor(name))\n",
    "                self.labels.append(label)\n",
    "        # labels to tensor\n",
    "        self.labels_uniq = list(labels_set)\n",
    "        for idx in range(len(self.labels)):\n",
    "            # the tensor of the label is its index in the list of unique labels\n",
    "            temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n",
    "            self.labels_tensors.append(temp_tensor)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        data_item = self.data[idx]\n",
    "        data_label = self.labels[idx]\n",
    "        data_tensor = self.data_tensors[idx]\n",
    "        label_tensor = self.labels_tensors[idx]\n",
    "\n",
    "        return label_tensor, data_tensor, data_label, data_item"
   ],
   "id": "bc26c89cd29a9512",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T05:01:52.431538Z",
     "start_time": "2025-07-22T05:01:50.209390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alldata = NamesDataset(\"./data/names\")\n",
    "print(f\"[DATA] Loaded {len(alldata)} names\")\n",
    "print(f\"[EXAMPLE]\")\n",
    "print(alldata[0])"
   ],
   "id": "e86d1c710758365d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] Loaded 20074 names\n",
      "[EXAMPLE]\n",
      "(tensor([17], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]], device='cuda:0'), 'Vietnamese', 'Nguyen')\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T05:08:51.106463Z",
     "start_time": "2025-07-22T05:08:51.062506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here we are using Generator to set the device as gpu\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    alldata,\n",
    "    [0.85, 0.15],\n",
    "    generator=torch.Generator(device=device).manual_seed(2025)\n",
    ")\n",
    "\n",
    "print(f\"[TRAIN] {len(train_set)} examples\")\n",
    "print(f\"[TEST] {len(test_set)} examples\")\n"
   ],
   "id": "cf202532bb09284b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] 17063 examples\n",
      "[TEST] 3011 examples\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the network",
   "id": "b614b5fa03336402"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
